{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    0.Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fayas\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries\r\n",
    "import os\r\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\n",
    "import random\r\n",
    "import gym\r\n",
    "import numpy as np\r\n",
    "from collections import deque\r\n",
    "from tensorflow.keras.models import Model, load_model,Sequential\r\n",
    "from tensorflow.keras.layers import Input, Dense,Flatten\r\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\r\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Importing an Open AI Gym Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fayas\\Anaconda3\\envs\\tf\\lib\\site-packages\\gym\\envs\\registration.py:506: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1` with the environment ID `CartPole-v1`.\u001b[0m\n",
      "  f\"The environment {path} is out of date. You should consider \"\n"
     ]
    }
   ],
   "source": [
    "# Importing the cartpole environment from openAi gym\r\n",
    "env = gym.make('CartPole-v0')\r\n",
    "actions = env.action_space.n\r\n",
    "states = env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Test with the imported OpenAi Gym game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:16.0\n",
      "Episode:2 Score:11.0\n",
      "Episode:3 Score:12.0\n",
      "Episode:4 Score:14.0\n",
      "Episode:5 Score:10.0\n",
      "Episode:6 Score:14.0\n",
      "Episode:7 Score:20.0\n",
      "Episode:8 Score:19.0\n",
      "Episode:9 Score:12.0\n",
      "Episode:10 Score:37.0\n",
      "Episode:11 Score:11.0\n",
      "Episode:12 Score:14.0\n",
      "Episode:13 Score:13.0\n",
      "Episode:14 Score:14.0\n",
      "Episode:15 Score:17.0\n",
      "Episode:16 Score:30.0\n",
      "Episode:17 Score:17.0\n",
      "Episode:18 Score:15.0\n",
      "Episode:19 Score:28.0\n",
      "Episode:20 Score:22.0\n",
      "Episode:21 Score:18.0\n",
      "Episode:22 Score:13.0\n",
      "Episode:23 Score:32.0\n",
      "Episode:24 Score:17.0\n",
      "Episode:25 Score:10.0\n",
      "Episode:26 Score:14.0\n",
      "Episode:27 Score:10.0\n",
      "Episode:28 Score:36.0\n",
      "Episode:29 Score:16.0\n",
      "Episode:30 Score:15.0\n",
      "Episode:31 Score:19.0\n",
      "Episode:32 Score:26.0\n",
      "Episode:33 Score:12.0\n",
      "Episode:34 Score:17.0\n",
      "Episode:35 Score:18.0\n",
      "Episode:36 Score:9.0\n",
      "Episode:37 Score:15.0\n",
      "Episode:38 Score:22.0\n",
      "Episode:39 Score:13.0\n",
      "Episode:40 Score:19.0\n",
      "Episode:41 Score:11.0\n",
      "Episode:42 Score:16.0\n",
      "Episode:43 Score:66.0\n",
      "Episode:44 Score:22.0\n",
      "Episode:45 Score:14.0\n",
      "Episode:46 Score:13.0\n",
      "Episode:47 Score:24.0\n",
      "Episode:48 Score:26.0\n",
      "Episode:49 Score:23.0\n",
      "Episode:50 Score:14.0\n",
      "Episode:51 Score:51.0\n",
      "Episode:52 Score:13.0\n",
      "Episode:53 Score:27.0\n",
      "Episode:54 Score:11.0\n",
      "Episode:55 Score:13.0\n",
      "Episode:56 Score:20.0\n",
      "Episode:57 Score:24.0\n",
      "Episode:58 Score:19.0\n",
      "Episode:59 Score:11.0\n",
      "Episode:60 Score:27.0\n",
      "Episode:61 Score:36.0\n",
      "Episode:62 Score:27.0\n",
      "Episode:63 Score:14.0\n",
      "Episode:64 Score:14.0\n",
      "Episode:65 Score:42.0\n",
      "Episode:66 Score:18.0\n",
      "Episode:67 Score:43.0\n",
      "Episode:68 Score:16.0\n",
      "Episode:69 Score:13.0\n",
      "Episode:70 Score:13.0\n",
      "Episode:71 Score:16.0\n",
      "Episode:72 Score:14.0\n",
      "Episode:73 Score:25.0\n",
      "Episode:74 Score:24.0\n",
      "Episode:75 Score:19.0\n",
      "Episode:76 Score:24.0\n",
      "Episode:77 Score:12.0\n",
      "Episode:78 Score:11.0\n",
      "Episode:79 Score:17.0\n",
      "Episode:80 Score:43.0\n",
      "Episode:81 Score:10.0\n",
      "Episode:82 Score:30.0\n",
      "Episode:83 Score:22.0\n",
      "Episode:84 Score:37.0\n",
      "Episode:85 Score:16.0\n",
      "Episode:86 Score:43.0\n",
      "Episode:87 Score:18.0\n",
      "Episode:88 Score:11.0\n",
      "Episode:89 Score:33.0\n",
      "Episode:90 Score:16.0\n",
      "Episode:91 Score:9.0\n",
      "Episode:92 Score:45.0\n",
      "Episode:93 Score:10.0\n",
      "Episode:94 Score:29.0\n",
      "Episode:95 Score:26.0\n",
      "Episode:96 Score:21.0\n",
      "Episode:97 Score:13.0\n",
      "Episode:98 Score:19.0\n",
      "Episode:99 Score:15.0\n",
      "Episode:100 Score:18.0\n"
     ]
    }
   ],
   "source": [
    "# testing the environment with random actions\r\n",
    "episodes = 100\r\n",
    "for episode in range(1, episodes+1):\r\n",
    "    state = env.reset()\r\n",
    "    done = False\r\n",
    "    score = 0 \r\n",
    "    \r\n",
    "    while not done:\r\n",
    "        env.render()\r\n",
    "        action = random.choice([0,1])\r\n",
    "        n_state, reward, done, info = env.step(action)\r\n",
    "        score+=reward\r\n",
    "    print('Episode:{} Score:{}'.format(episode, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. Creating a Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a neural network model with keras\r\n",
    "def neural_model(states, actions):\r\n",
    "    X_input = Input(states)\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Flatten(input_shape=states))\r\n",
    "    #model.add(Dense(512, activation='relu'))\r\n",
    "    model.add(Dense(24, activation='relu'))\r\n",
    "    model.add(Dense(24, activation='relu'))\r\n",
    "    model.add(Dense(actions, activation='linear'))\r\n",
    "    model.compile(loss='mse',optimizer=Adam(learning_rate=0.001))\r\n",
    "\r\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a model object\r\n",
    "model = neural_model((states,), actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3.Connecting game to the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for the DQN algorithm\r\n",
    "EPISODES = 300\r\n",
    "\r\n",
    "EXPLORATION_MAX= 1.0\r\n",
    "EXPLORATION_MIN = 0.001\r\n",
    "EXPLORATION_DECAY = 0.999\r\n",
    "\r\n",
    "GAMMA = 0.95\r\n",
    "LEARNING_RATE = 0.001\r\n",
    "\r\n",
    "MEMORY_SIZE = 10000\r\n",
    "BATCH_SIZE = 64\r\n",
    "\r\n",
    "TRAIN_START = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the class for the DQN algorithm\r\n",
    "class DQNSolver:\r\n",
    "    \r\n",
    "    ''' Deep Q Neural Network class. '''\r\n",
    "\r\n",
    "    #initializing the model parameters\r\n",
    "    def __init__(self, states, actions,model):\r\n",
    "        self.exp_rate = EXPLORATION_MAX\r\n",
    "        self.action_choice = actions\r\n",
    "        self.memory = deque(maxlen=MEMORY_SIZE)\r\n",
    "        self.model = model\r\n",
    "\r\n",
    "    # appending the values to the memory table\r\n",
    "    def DQN_table(self, state, action, reward, next_state, done):\r\n",
    "        self.memory.append((state, action, reward, next_state, done))\r\n",
    "        if len(self.memory) > TRAIN_START:\r\n",
    "            if self.exp_rate > EXPLORATION_MIN:\r\n",
    "                self.exp_rate *= EXPLORATION_DECAY\r\n",
    "\r\n",
    "\r\n",
    "    # play function to choose the action based on exploration rate\r\n",
    "    def play(self, state):\r\n",
    "        if np.random.rand() < self.exp_rate:\r\n",
    "            return random.randrange(self.action_choice)\r\n",
    "        q_val = self.model.predict(state)\r\n",
    "        return np.argmax(q_val[0])\r\n",
    "\r\n",
    "    # defining the experience_replay function to store the experience in the memory\r\n",
    "    def experience_replay(self):\r\n",
    "        if len(self.memory) < TRAIN_START:\r\n",
    "            return\r\n",
    "        batch = random.sample(self.memory, BATCH_SIZE)\r\n",
    "        for state, action, reward, next_state, terminal in batch:\r\n",
    "            qval_update = reward\r\n",
    "            if not terminal:\r\n",
    "                qval_update = (reward + GAMMA * np.amax(self.model.predict(next_state)[0]))\r\n",
    "            q_val = self.model.predict(state)\r\n",
    "            q_val[0][action] = qval_update\r\n",
    "            self.model.fit(state, q_val, verbose=0)\r\n",
    "        self.exp_rate *= EXPLORATION_DECAY\r\n",
    "        self.exp_rate = max(EXPLORATION_MIN, self.exp_rate)\r\n",
    "\r\n",
    "    # function to save the model    \r\n",
    "    def save(self,name):\r\n",
    "         \r\n",
    "         self.model.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list variables to store the values for plotting\r\n",
    "plotScores=[]\r\n",
    "plotepsilon=[] \r\n",
    "plotsteps = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the DQN algorithm\r\n",
    "def training():\r\n",
    "    \r\n",
    "    dqn_solver = DQNSolver(states, actions,model)\r\n",
    "    run = 0\r\n",
    "    for run in range(EPISODES):\r\n",
    "        score = 0\r\n",
    "        state = env.reset()\r\n",
    "        state = np.reshape(state, [1, states])\r\n",
    "        iter = 0\r\n",
    "        terminal = False\r\n",
    "        while not terminal:\r\n",
    "            iter += 1\r\n",
    "            env.render()\r\n",
    "            action = dqn_solver.play(state)\r\n",
    "            next_state, reward, terminal, info = env.step(action)\r\n",
    "            reward = reward if not terminal else -100\r\n",
    "            score += reward\r\n",
    "            next_state = np.reshape(next_state, [1, states])\r\n",
    "            dqn_solver.DQN_table(state, action, reward, next_state, terminal)\r\n",
    "            state = next_state\r\n",
    "            if terminal:\r\n",
    "                plotScores.append(score)\r\n",
    "                #plotScores.append(iter)\r\n",
    "                plotepsilon.append(dqn_solver.exp_rate)\r\n",
    "                plotsteps.append(run)\r\n",
    "                print (\"Run: \" + str(run) + \" / \" + str(EPISODES) + \", exploration: \" + str(dqn_solver.exp_rate)+ \", score:\"  + str(score))\r\n",
    "                if run == 100 or run == 299 or run == 1000:\r\n",
    "                    print(\"Saving trained model as cartpole_weights\"+str(run)+\".h5\")\r\n",
    "                    dqn_solver.save('cartpole_weights'+str(run)+'.h5')\r\n",
    "                break\r\n",
    "            dqn_solver.experience_replay()\r\n",
    "        \r\n",
    "    return plotScores,plotepsilon,plotsteps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0 / 300, exploration: 1.0, score:-80.0\n",
      "Run: 1 / 300, exploration: 1.0, score:-65.0\n",
      "Run: 2 / 300, exploration: 1.0, score:-64.0\n",
      "Run: 3 / 300, exploration: 1.0, score:-85.0\n",
      "Run: 4 / 300, exploration: 1.0, score:-87.0\n",
      "Run: 5 / 300, exploration: 1.0, score:-92.0\n",
      "Run: 6 / 300, exploration: 1.0, score:-89.0\n",
      "Run: 7 / 300, exploration: 1.0, score:-84.0\n",
      "Run: 8 / 300, exploration: 1.0, score:-91.0\n",
      "Run: 9 / 300, exploration: 1.0, score:-83.0\n",
      "Run: 10 / 300, exploration: 1.0, score:-54.0\n",
      "Run: 11 / 300, exploration: 1.0, score:-89.0\n",
      "Run: 12 / 300, exploration: 1.0, score:-82.0\n",
      "Run: 13 / 300, exploration: 1.0, score:-79.0\n",
      "Run: 14 / 300, exploration: 1.0, score:-61.0\n",
      "Run: 15 / 300, exploration: 1.0, score:-81.0\n",
      "Run: 16 / 300, exploration: 1.0, score:-83.0\n",
      "Run: 17 / 300, exploration: 1.0, score:-88.0\n",
      "Run: 18 / 300, exploration: 1.0, score:-25.0\n",
      "Run: 19 / 300, exploration: 1.0, score:-90.0\n",
      "Run: 20 / 300, exploration: 1.0, score:-81.0\n",
      "Run: 21 / 300, exploration: 1.0, score:-68.0\n",
      "Run: 22 / 300, exploration: 1.0, score:-77.0\n",
      "Run: 23 / 300, exploration: 1.0, score:-80.0\n",
      "Run: 24 / 300, exploration: 1.0, score:-76.0\n",
      "Run: 25 / 300, exploration: 1.0, score:-58.0\n",
      "Run: 26 / 300, exploration: 1.0, score:-85.0\n",
      "Run: 27 / 300, exploration: 1.0, score:-74.0\n",
      "Run: 28 / 300, exploration: 1.0, score:-32.0\n",
      "Run: 29 / 300, exploration: 1.0, score:-78.0\n",
      "Run: 30 / 300, exploration: 1.0, score:-89.0\n",
      "Run: 31 / 300, exploration: 1.0, score:-80.0\n",
      "Run: 32 / 300, exploration: 1.0, score:-78.0\n",
      "Run: 33 / 300, exploration: 1.0, score:-51.0\n",
      "Run: 34 / 300, exploration: 1.0, score:-90.0\n",
      "Run: 35 / 300, exploration: 1.0, score:-88.0\n",
      "Run: 36 / 300, exploration: 1.0, score:-89.0\n",
      "Run: 37 / 300, exploration: 1.0, score:-79.0\n",
      "Run: 38 / 300, exploration: 1.0, score:-83.0\n",
      "Run: 39 / 300, exploration: 1.0, score:-67.0\n",
      "Run: 40 / 300, exploration: 1.0, score:-91.0\n",
      "Run: 41 / 300, exploration: 0.9607702107358118, score:-76.0\n",
      "Run: 42 / 300, exploration: 0.933294459381294, score:-86.0\n",
      "Run: 43 / 300, exploration: 0.8904235427767183, score:-77.0\n"
     ]
    }
   ],
   "source": [
    "plotScores,plotepsilon,plotsteps = training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-84.0,\n",
       " -72.0,\n",
       " -79.0,\n",
       " -78.0,\n",
       " -73.0,\n",
       " -84.0,\n",
       " -65.0,\n",
       " -86.0,\n",
       " -70.0,\n",
       " -66.0,\n",
       " -85.0,\n",
       " -75.0,\n",
       " -69.0,\n",
       " -76.0,\n",
       " -64.0,\n",
       " -80.0,\n",
       " -62.0,\n",
       " -88.0,\n",
       " -71.0,\n",
       " -79.0,\n",
       " -69.0,\n",
       " -78.0,\n",
       " -76.0,\n",
       " -73.0,\n",
       " -53.0,\n",
       " -89.0,\n",
       " -84.0,\n",
       " -87.0,\n",
       " -91.0,\n",
       " -87.0,\n",
       " -90.0,\n",
       " -85.0,\n",
       " -85.0,\n",
       " -80.0,\n",
       " -62.0]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4. Implementing the deep reinforcement learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\r\n",
    "def load(name):\r\n",
    "        return load_model(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model with our trained model weights\r\n",
    "def testing(state_size):\r\n",
    "    load('cartpole_weights29.h5')\r\n",
    "    for run in range(EPISODES):\r\n",
    "        state = env.reset()\r\n",
    "        state = np.reshape(state, [1,state_size])\r\n",
    "        terminal = False\r\n",
    "        score = 0\r\n",
    "        iter = 0\r\n",
    "        while not terminal:\r\n",
    "            iter += 1\r\n",
    "            env.render()\r\n",
    "            action = np.argmax(model.predict(state))\r\n",
    "            next_state, reward, terminal, info = env.step(action)\r\n",
    "            score += reward\r\n",
    "            state = np.reshape(next_state, [1, state_size])\r\n",
    "            if done:\r\n",
    "                print (\"Run: \" + str(run) + \" / \" + str(EPISODES) + \", score: \" + str(score))\r\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0 / 35, score: 1.0\n",
      "Run: 1 / 35, score: 1.0\n",
      "Run: 2 / 35, score: 1.0\n",
      "Run: 3 / 35, score: 1.0\n",
      "Run: 4 / 35, score: 1.0\n",
      "Run: 5 / 35, score: 1.0\n",
      "Run: 6 / 35, score: 1.0\n",
      "Run: 7 / 35, score: 1.0\n",
      "Run: 8 / 35, score: 1.0\n",
      "Run: 9 / 35, score: 1.0\n",
      "Run: 10 / 35, score: 1.0\n",
      "Run: 11 / 35, score: 1.0\n",
      "Run: 12 / 35, score: 1.0\n",
      "Run: 13 / 35, score: 1.0\n",
      "Run: 14 / 35, score: 1.0\n",
      "Run: 15 / 35, score: 1.0\n",
      "Run: 16 / 35, score: 1.0\n",
      "Run: 17 / 35, score: 1.0\n",
      "Run: 18 / 35, score: 1.0\n",
      "Run: 19 / 35, score: 1.0\n",
      "Run: 20 / 35, score: 1.0\n",
      "Run: 21 / 35, score: 1.0\n",
      "Run: 22 / 35, score: 1.0\n",
      "Run: 23 / 35, score: 1.0\n",
      "Run: 24 / 35, score: 1.0\n",
      "Run: 25 / 35, score: 1.0\n",
      "Run: 26 / 35, score: 1.0\n",
      "Run: 27 / 35, score: 1.0\n",
      "Run: 28 / 35, score: 1.0\n",
      "Run: 29 / 35, score: 1.0\n",
      "Run: 30 / 35, score: 1.0\n",
      "Run: 31 / 35, score: 1.0\n",
      "Run: 32 / 35, score: 1.0\n",
      "Run: 33 / 35, score: 1.0\n",
      "Run: 34 / 35, score: 1.0\n"
     ]
    }
   ],
   "source": [
    "testing(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the rewards and epsilon values vs episodes\r\n",
    "\r\n",
    "def plot_learning_curves(x, scores,epsilons, filename, lines=None):\r\n",
    "    fig=plt.figure(figsize=(15,10))\r\n",
    "    ax=fig.add_subplot(121, label=\"1\")\r\n",
    "    ax2=fig.add_subplot(122, label=\"2\")\r\n",
    "        \r\n",
    "\r\n",
    "    ax.plot(x, epsilons, color=\"C0\")\r\n",
    "    ax.set_xlabel(\"Training Steps\", color=\"C0\")\r\n",
    "    ax.set_ylabel(\"Epsilon\", color=\"C0\")\r\n",
    "    ax.tick_params(axis='x', colors=\"C0\")\r\n",
    "    ax.tick_params(axis='y', colors=\"C0\")\r\n",
    "    ax.grid()\r\n",
    "    N = len(scores)\r\n",
    "    running_avg = np.empty(N)\r\n",
    "    for t in range(N):\r\n",
    "\t    running_avg[t] = np.mean(scores[max(0, t-20):(t+1)])\r\n",
    "\r\n",
    "    ax2.scatter(x, running_avg, color=\"C1\")\r\n",
    "    ax2.set_xlabel(\"Training Steps\", color=\"C0\")\r\n",
    "    ax2.yaxis.tick_right()\r\n",
    "    ax2.set_ylabel('Score', color=\"C1\")\r\n",
    "    ax2.yaxis.set_label_position('right')\r\n",
    "    ax2.tick_params(axis='x', colors=\"C0\")\r\n",
    "    ax2.tick_params(axis='y', colors=\"C1\")\r\n",
    "    ax2.grid()\r\n",
    "    if lines is not None:\r\n",
    "        for line in lines:\r\n",
    "            plt.axvline(x=line)\r\n",
    "\r\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFigure = 'plot1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curves(plotsteps, plotScores, plotepsilon, plotFigure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b42e8c54956ebe1e3ec306941cd06295d759e8aaba60cd117b7f75d747ffdee7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('tf': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}